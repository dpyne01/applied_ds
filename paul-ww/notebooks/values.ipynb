{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Initial Cleaning of the Ground Value Dataset\n",
    "## General Description\n",
    " As part of my project in the Tufts class EM212: Applied Datascience, I will\n",
    " try to analyse two datasets:\n",
    " *   the District Profiles (2007 to 2017) Dataset, containing socio-demographic information about Hamburg's districts\n",
    " *   the Ground Value (1964 to 2017) Dataset, containing estimates of the ground value of real estate in Hamburg,\n",
    " on an individual property level in Euros / $m^2$\n",
    "\n",
    "## Information on the Ground Value Dataset\n",
    " Each year, the city of Hamburg publishes rough estimates of the value of\n",
    " real estate on property level. The so-called \"Bodenrichtwert\" (abbr. BRW, \"reference ground value\")\n",
    " is the value of a particular property broken down to a $1m^2$ plot of land at a certain location (measured in coordinates).\n",
    " The calculation of the BRW takes the following features into account:\n",
    " *   location (x,y coordinates)\n",
    " *   suitability for development and use (categorical)\n",
    " *   current development / use (categorical)\n",
    " *   size of the plot\n",
    "\n",
    " A recent, detailed description of the data and the features used in the calculation is available\n",
    " [here (in German)](https://www.hamburg.de/contentblob/10917486/73e458aa8a5e46f772eacb2b00b4c393/data/d-brw-erlaeuterungen-2017.pdf).\n",
    " Additional information is available [here (also in German)](https://www.hamburg.de/bsw/grundstueckswerte/7916004/bodenrichtwert-erlaeuterungen/)\n",
    "\n",
    " The City of Hamburg makes this data available through its [Open Data Portal](http://suche.transparenz.hamburg.de/dataset/bodenrichtwerte-fur-hamburg6?forceWeb=true).\n",
    " Unfortunately, the data is split up into multiple CSV files, each representing\n",
    " one year of observations. In order to work with this dataset, I will download\n",
    " the individual CSVs, import them into pandas DataFrames, merge these together\n",
    " and save the result as a CSV file.\n",
    "\n",
    "## Heads Up:\n",
    " In order to download and process and store the data, about 4GB of free disk space is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import requests\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO, StringIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    " The next cell will download the compressed CSV files from Box. This should be much faster\n",
    " than getting them from the original source. If you prefer downloading them\n",
    " from the Open Data Portal directly, skip this cell and use the commented out\n",
    " code in the cells below. Otherwise, use this cell and proceed normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading zip file...\n",
      "Done.\n",
      "Reading file CSVs/br0200001-Hamburg1964.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1973.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1975.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1977.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1980.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1982.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1984.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1986.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1988.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1990.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1992.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1994.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1996.csv...\n",
      "Reading file CSVs/br0200001-Hamburg1998.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2000.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2002.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2004.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2006.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2008.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2010.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Paul/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file CSVs/br0200001-Hamburg2011.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2012.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2013.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Paul/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (12,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file CSVs/br0200001-Hamburg2014.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2015.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2016.csv...\n",
      "Reading file CSVs/br0200001-Hamburg2017.csv...\n",
      "Concatening dataframes...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://tufts.box.com/shared/static/r9v656dng1b0ncl3vhyc9mgph884aqk5.zip\"\n",
    "\n",
    "print(\"Downloading zip file...\")\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "zip = ZipFile(BytesIO(r.content))\n",
    "files = zip.namelist()\n",
    "print(\"Done.\")\n",
    "\n",
    "# filter out residual mac files (DS store and such)\n",
    "csvs = [file for file in files if (not \"__\" in file) and (\"br\" in file)]\n",
    "csvs.sort()\n",
    "\n",
    "dfs = []\n",
    "for file in csvs:\n",
    "    print(\"Reading file \" + file + \"...\")\n",
    "    with zip.open(file) as csvfile:\n",
    "        dfs.append(pd.read_csv( csvfile,\n",
    "                                sep=\"|\",\n",
    "                                header=0,\n",
    "                                encoding=\"ISO-8859-1\" # this encoding seems to be correct\n",
    "                                ))\n",
    "print(\"Concatening dataframes...\")\n",
    "data = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download from original source\n",
    " Only execute the next cell if you would like to download the whole dataset.\n",
    " The cell will take a long time to complete, as the server does not seem to offer\n",
    " fast download speeds. I have therefore commented out this section so that it\n",
    " does not run automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# with open(\"urls.txt\") as file:\n",
    "#     urls = [line.rstrip('\\n') for line in file]\n",
    "#\n",
    "# def download(urls):\n",
    "#     '''Downloads the files specified in list urls'''\n",
    "#     for url in urls:\n",
    "#         successful = 0\n",
    "#         count = len(urls)\n",
    "#         filename = url.rsplit('/', 1)[1]\n",
    "#         print(\"Downloading \" + filename + \" (\" + str(successful) + \"/\" + str(count) + \" completed)...\")\n",
    "#         r = requests.get(url, allow_redirects=True)\n",
    "#         open(filename, 'wb').write(r.content)\n",
    "#         print(\"Done.\")\n",
    "#         current += 1\n",
    "#\n",
    "# download(urls) # start the download\n",
    "#\n",
    "# # read downloaded CSV files\n",
    "# files = glob.glob(\"*.csv\") # aggregate all csv files for reading\n",
    "# files = sorted(files) # sort files to start with the smallest one\n",
    "# files\n",
    "#\n",
    "# # import the data from the CSV files\n",
    "# dfs = []\n",
    "# for file in files:\n",
    "#     print(\"Reading file \" + file + \"...\")\n",
    "#     dfs.append(pd.read_csv( file,\n",
    "#                             sep=\"|\",\n",
    "#                             header=0,\n",
    "#                             encoding=\"ISO-8859-1\" # this encoding seems to be correct\n",
    "#                             ))\n",
    "# print(\"Concatening dataframes...\")\n",
    "# data = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "# print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Survey and Cleaning\n",
    " Let's take a look at the data. It seems like there are many columns where a\n",
    " common ```dtype``` could not be recognized. Because of this, the dataset takes\n",
    " up much more storage space than it would if the ```dtypes``` were set properly.\n",
    " This should be the first priority before saving the joined dataset to save storage\n",
    " space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2049911 entries, 0 to 2049910\n",
      "Data columns (total 47 columns):\n",
      "GESL        int64\n",
      "GENA        object\n",
      "GASL        int64\n",
      "GABE        object\n",
      "GENU        float64\n",
      "GEMA        float64\n",
      "ORTST       object\n",
      "WNUM        int64\n",
      "BRW         float64\n",
      "STAG        object\n",
      "BRKE        int64\n",
      "BEDW        float64\n",
      "PLZ         object\n",
      "BASBE       object\n",
      "BASMA       int64\n",
      "YWERT       int64\n",
      "XWERT       int64\n",
      "BEZUG       object\n",
      "ENTW        object\n",
      "BEIT        float64\n",
      "NUTA        object\n",
      "ERGNUTA     object\n",
      "BAUW        object\n",
      "GEZ         float64\n",
      "WGFZ        float64\n",
      "GRZ         float64\n",
      "BMZ         float64\n",
      "FLAE        float64\n",
      "GTIE        float64\n",
      "GBREI       float64\n",
      "ERVE        float64\n",
      "VERG        object\n",
      "VERF        object\n",
      "YVERG       float64\n",
      "XVERG       float64\n",
      "BOD         float64\n",
      "ACZA        float64\n",
      "GRZA        float64\n",
      "AUFW        float64\n",
      "WEER        float64\n",
      "KOORWERT    object\n",
      "KOORVERF    object\n",
      "BEM         object\n",
      "FREI        object\n",
      "BRZNAME     object\n",
      "UMDART      int64\n",
      "LUMNUM      object\n",
      "dtypes: float64(20), int64(8), object(19)\n",
      "memory usage: 735.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.head(5)\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [dataset metadata information sheet](https://www.hamburg.de/contentblob/8025502/a106909f7f9c11b8d90312a99a5b62c8/data/d-vboris-modellbeschreibung.pdf),\n",
    "I have the following list of\n",
    "variable names and their description. I will first identify those that I will\n",
    "not be using in my data analysis and can thus drop:\n",
    "\n",
    "| Variable Name | Description                                      | ```dtype``` / drop |\n",
    "|---------------|--------------------------------------------------|--------------------|\n",
    "| GESL          | Ward (code)                                      | drop               |\n",
    "| GENA          | Ward (name)                                      | drop               |\n",
    "| GASL          | Surveying institution (code)                     | drop               |\n",
    "| GABE          | Surveying institution (name)                     | drop               |\n",
    "| GENU          | Land Survey Registry (code)                      | drop               |\n",
    "| GEMA          | Land Survey Registry (name)                      | drop               |\n",
    "| ORTST         | District (name)                                  | category           |\n",
    "| WNUM          | Ground Value Number (code)                       | drop               |\n",
    "| BRW           | Ground Value                                     | float              |\n",
    "| STAG          | Observation / Survey Date                        | date (dd.mm.yyyy)  |\n",
    "| BRKE          | kind of ground value                             | integer            |\n",
    "| BEDW          | \"Requirements value\"                             | drop               |\n",
    "| PLZ           | zip code                                         | integer            |\n",
    "| BASBE         | base map reference                               | drop               |\n",
    "| BASMA         | base map scale                                   | drop               |\n",
    "| YWERT         | BRW geo-reference (east)                         | integer            |\n",
    "| XWERT         | BRW geo-reference (north)                        | integer            |\n",
    "| BEZUG         | coordinate system used                           | drop               |\n",
    "| ENTW          | current state of development                     | category           |\n",
    "| BEIT          | development state according to taxes             | category           |\n",
    "| NUTA          | kind of current usage                            | category           |\n",
    "| ERGNUTA       | extension of NUTA                                | category           |\n",
    "| BAUW          | current building type                            | category           |\n",
    "| GEZ           | number of floors                                 | float              |\n",
    "| WGFZ          | number of floors relevant for BRW                | float              |\n",
    "| GRZ           | site coverage factor                             | float              |\n",
    "| BMZ           | cubic index                                      | float              |\n",
    "| FLAE          | site area  in $m^2$                              | float              |\n",
    "| GTIE          | site depth  in meters                            | float              |\n",
    "| GBREI         | site width in meters                             | float              |\n",
    "| ERVE          | accessibility                                    | category           |\n",
    "| VERG          | zoning city development information              | category           |\n",
    "| VERF          | state of remediation                             | category           |\n",
    "| YVERG         | coordinate of city planning measure (east)       | drop               |\n",
    "| XVERG         | coordinate of city planning measure (north)      | drop               |\n",
    "| BOD           | kind of ground                                   | float              |\n",
    "| ACZA          | index value of agricultural land                 | drop               |\n",
    "| GRZA          | index value of agricultural land                 | drop               |\n",
    "| AUFW          | historical reference for reforestation           | drop               |\n",
    "| WEER          | accessible roads for agriculture / forestry      | drop               |\n",
    "| KOORWERT      | geo-reference polygon for BRW zone               | drop               |\n",
    "| KOORVERF      | geo-reference polygon for city planning measures | drop               |\n",
    "| BEM           | notes                                            | drop               |\n",
    "\n",
    "As a first step, I will mark the selected columns to be dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "cols_to_drop = [    \"GESL\", \"GENA\", \"GASL\", \"GABE\", \"GENU\", \"GEMA\",\n",
    "                    \"WNUM\", \"BEDW\", \"BASBE\", \"BASMA\", \"BEZUG\", \"YVERG\",\n",
    "                    \"XVERG\", \"ACZA\", \"GRZA\", \"AUFW\", \"WEER\", \"KOORWERT\",\n",
    "                    \"KOORVERF\", \"BEM\" ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will list all columns that were not detected as being numerical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENA</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GABE</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORTST</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAG</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLZ</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BASBE</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BEZUG</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENTW</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NUTA</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ERGNUTA</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BAUW</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VERG</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VERF</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KOORWERT</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KOORVERF</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BEM</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FREI</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BRZNAME</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LUMNUM</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index       0\n",
       "0       GENA  object\n",
       "1       GABE  object\n",
       "2      ORTST  object\n",
       "3       STAG  object\n",
       "4        PLZ  object\n",
       "5      BASBE  object\n",
       "6      BEZUG  object\n",
       "7       ENTW  object\n",
       "8       NUTA  object\n",
       "9    ERGNUTA  object\n",
       "10      BAUW  object\n",
       "11      VERG  object\n",
       "12      VERF  object\n",
       "13  KOORWERT  object\n",
       "14  KOORVERF  object\n",
       "15       BEM  object\n",
       "16      FREI  object\n",
       "17   BRZNAME  object\n",
       "18    LUMNUM  object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numerical = pd.DataFrame(data.select_dtypes(exclude=\"number\").dtypes).reset_index()\n",
    "non_numerical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that there are some column that are empty or that only contain one value.\n",
    "I wrote a function that should check each column for this condition and then\n",
    "save its only value and mark it to be dropped from the main dataset.\n",
    "\n",
    "The following columns appear to be empty or contain only one value, which has been saved in\n",
    "´´´saved_info´´´. They can thus be dropped from the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>only value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENA</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GASL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEMA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BEDW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BEZUG</td>\n",
       "      <td>ETRS89_UTM32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GEZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GRZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BMZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GBREI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ERVE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AUFW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WEER</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UMDART</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    column    only value\n",
       "0     GENA       Hamburg\n",
       "1     GASL             1\n",
       "2     GENU           NaN\n",
       "3     GEMA           NaN\n",
       "4     BEDW           NaN\n",
       "5    BEZUG  ETRS89_UTM32\n",
       "6      GEZ           NaN\n",
       "7      GRZ           NaN\n",
       "8      BMZ           NaN\n",
       "9    GBREI           NaN\n",
       "10    ERVE           NaN\n",
       "11     BOD           NaN\n",
       "12    AUFW           NaN\n",
       "13    WEER           NaN\n",
       "14  UMDART             0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_info = {} # dictionary for info that might be useful, but does not need to be in dataframe\n",
    "\n",
    "def save_info_and_mark(drop=cols_to_drop, save=saved_info, df=data):\n",
    "    \"\"\"If a column only contains one unique value, save it into save and mark to column to be dropped\"\"\"\n",
    "    for column in df:\n",
    "        unique_values = df[column].unique()\n",
    "        if len(unique_values) == 1:\n",
    "            save[column] = df[column].unique()[0]\n",
    "            if column not in drop:\n",
    "                drop.append(column)\n",
    "    return save, drop\n",
    "\n",
    "# iterate over all columns in non-numerical and check for columns containing only one value,\n",
    "# save its content and mark it to be dropped\n",
    "saved_info, cols_to_drop = save_info_and_mark()\n",
    "\n",
    "almost_empty = pd.DataFrame(saved_info, index=[0]).transpose().reset_index() # show the stored content\n",
    "almost_empty.columns = [\"column\", \"only value\"]\n",
    "almost_empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to actually drop the columns that I earmarked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "data.drop(columns=cols_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the remaining columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORTST': array(['Rissen', 'Iserbrook', 'Osdorf', 'Lurup', 'Othmarschen',\n",
       "        'Bahrenfeld', 'Eidelstedt', 'Schnelsen', 'Hausbruch', 'Stellingen',\n",
       "        'Eißendorf', 'Altona-Nord', 'Altona-Altstadt', 'Lokstedt',\n",
       "        'Niendorf', 'Harburg', 'St. Pauli', 'Hamburg-Altstadt',\n",
       "        'Rotherbaum', 'Eppendorf', 'Groß Borstel', 'Langenhorn',\n",
       "        'Wilstorf', 'Langenbek', 'Wilhelmsburg', 'Klostertor',\n",
       "        'Winterhude', 'Fuhlsbüttel', 'Barmbek-Süd', 'Hummelsbüttel',\n",
       "        'Eilbek', 'Marienthal', 'Bramfeld', 'Steilshoop', 'Poppenbüttel',\n",
       "        'Lemsahl-Mellingstedt', 'Allermöhe', 'Moorfleet', 'Wandsbek',\n",
       "        'Farmsen-Berne', 'Jenfeld', 'Tonndorf', 'Rahlstedt', 'Lohbrügge',\n",
       "        'Bergedorf', 'Neuenfelde', 'Cranz', 'Blankenese',\n",
       "        'Neugraben-Fischbek', 'Sülldorf', 'Francop', 'Nienstedten',\n",
       "        'Finkenwerder', 'Groß Flottbek', 'Moorburg', 'Heimfeld',\n",
       "        'Ottensen', 'Marmstorf', 'Sinstorf', 'Eimsbüttel', 'Hoheluft-West',\n",
       "        'Neustadt', 'Harvestehude', 'Hoheluft-Ost', 'Alsterdorf',\n",
       "        'Rönneburg', 'Neuland', 'Gut Moor', 'Kleiner Grasbrook', 'Veddel',\n",
       "        'St. Georg', 'Hammerbrook', 'Hohenfelde', 'Uhlenhorst', 'Ohlsdorf',\n",
       "        'Rothenburgsort', 'Hamm-Süd', 'Borgfelde', 'Hamm-Mitte',\n",
       "        'Hamm-Nord', 'Barmbek-Nord', 'Dulsberg', 'Ochsenwerder',\n",
       "        'Tatenberg', 'Spadenland', 'Billbrook', 'Horn', 'Wellingsbüttel',\n",
       "        'Duvenstedt', 'Billstedt', 'Sasel', 'Bergstedt', 'Kirchwerder',\n",
       "        'Reitbrook', 'Billwerder', 'Volksdorf', 'Wohldorf-Ohlstedt',\n",
       "        'Neuengamme', 'Curslack', 'Altengamme', 'Altenwerder', 'Neuwerk',\n",
       "        'Sternschanze', 'Steinwerder', 'HafenCity', 'Waltershof', 'Hamm',\n",
       "        'Neuallermöhe', 'GroÃ\\x9f Flottbek', 'SÃ¼lldorf', 'EimsbÃ¼ttel',\n",
       "        'GroÃ\\x9f Borstel', 'Barmbek-SÃ¼d', 'FuhlsbÃ¼ttel',\n",
       "        'WellingsbÃ¼ttel', 'PoppenbÃ¼ttel', 'HummelsbÃ¼ttel', 'LohbrÃ¼gge',\n",
       "        'AllermÃ¶he', 'RÃ¶nneburg', 'EiÃ\\x9fendorf', 'NeuallermÃ¶he'],\n",
       "       dtype=object),\n",
       " 'STAG': array(['01.01.1964', '31.12.1973', '31.12.1975', '31.12.1977',\n",
       "        '31.12.1980', '31.12.1982', '31.12.1984', '31.12.1986',\n",
       "        '31.12.1988', '31.12.1990', '31.12.1992', '31.12.1994',\n",
       "        '01.01.1996', '01.01.1998', '01.01.2000', '01.01.2002',\n",
       "        '01.01.2004', '01.01.2006', '01.01.2008', '31.12.2010',\n",
       "        '31.12.2011', '31.12.2012', '31.12.2013', '31.12.2014',\n",
       "        '31.12.2015', '31.12.2016', '31.12.2017'], dtype=object),\n",
       " 'PLZ': array([22559, 22589, 22609, 22549, 22605, 22761, 22547, 22525, 22523,\n",
       "        22457, 21147, 21073, 22765, 22769, 22527, 22529, 22453, 22459,\n",
       "        22455, 21079, 20359, 20457, 20148, 22419, 21109, 20097, 20095,\n",
       "        22299, 22415, 22335, 22083, 22339, 22089, 22041, 22177, 22179,\n",
       "        22309, 22399, 22397, 21035, 22113, 22047, 22159, 22175, 22391,\n",
       "        22045, 22043, 22143, 21031, 22145, 21129, 22587, 21149, 22607,\n",
       "        22763, 25469, 21077, 21075, 21107, 22767, 20357, 20259, 20257,\n",
       "        20255, 20253, 20459, 20355, 20354, 20146, 20144, 20149, 20249,\n",
       "        20251, 22297, 20539, 20099, 22087, 22085, 22301, 22303, 22337,\n",
       "        22417, 20537, 20535, 22081, 22305, 22307, 21037, 22111, 21509,\n",
       "        22049, 22117, 22119, 22393, 22395, 21033, 22115, 22149, 22147,\n",
       "        22359, 21029, 21039, 22869, 27499, 22880, 25462, 21217, 21629,\n",
       "        21635, 22885, 22889, 21218, 21224, '21077', '21079', '21217',\n",
       "        '21075', '21073', '21149', '21129', '21147', '21629', '21635',\n",
       "        '20535', '20537', '22111', '22119', '22117', '22115', '22113',\n",
       "        '20539', '21109', '21107', '20457', '22767', '22769', '22525',\n",
       "        '22761', '22607', '22609', '22605', '22763', '22547', '22549',\n",
       "        '22589', '22587', '22559', '20257', '20146', '20148', '20144',\n",
       "        '22529', '22527', '22455', '22453', '22459', '22457', '25462',\n",
       "        '22523', '20251', '20249', '22297', '22335', '22337', '22299',\n",
       "        '22303', '22301', '22085', '22087', '22305', '22307', '22339',\n",
       "        '22419', '22417', '22415', '22089', '22041', '22049', '22047',\n",
       "        '22043', '22045', '22885', '22159', '22145', '22147', '22175',\n",
       "        '22177', '22179', '22309', '22391', '22395', '22393', '22399',\n",
       "        '22397', '22359', '22143', '22149', '21033', '21031', '21035',\n",
       "        '21029', '21039', '21037', '20259', '27499', '20149', '22081',\n",
       "        '224^9', '22765', '20095', '20099', '20459', '20355', '20354',\n",
       "        '20357', '20359', '20097', '25469', '22869', '20255', '20253',\n",
       "        '22083', '21218', '21224', '22889', '22880', 21028], dtype=object),\n",
       " 'ENTW': array(['B', 'SF', 'R', 'L', 'LF'], dtype=object),\n",
       " 'NUTA': array(['M', 'CA', 'SPO', 'A', 'GR', 'F', 'EGA', 'LW'], dtype=object),\n",
       " 'ERGNUTA': array(['EFH', 'BGH', 'LAD', 'MFH', 'BH', 'PL', 'EKZ', 'CA', 'WGH', 'SPO',\n",
       "        'GH', nan, 'GEM'], dtype=object),\n",
       " 'BAUW': array(['rm', 'eh', nan, 'a', 'g', 'dh'], dtype=object),\n",
       " 'VERG': array([nan, 'San'], dtype=object),\n",
       " 'VERF': array([nan, 'SB'], dtype=object),\n",
       " 'FREI': array(['031.012.1977;22;WR II RH  ;(2-geschossig)                                              ;   14,32;        ;        ;        ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;',\n",
       "        '031.012.1977;11;WR I      ;(1-geschossig)                                              ;   37,32;        ;        ;        ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;',\n",
       "        '031.012.1977;11;WR I      ;(1-geschossig)                                              ;   18,41;        ;        ;        ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;',\n",
       "        ...,\n",
       "        '          ;92;GR        ;                                                            ;    6,36;        ;        ;        ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ',\n",
       "        '          ;93;EGA       ;                                                            ;    6,58;        ;        ;        ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ',\n",
       "        '          ;96;F         ;                                                            ;    3,63;        ;        ;        ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        ;          ;    ;        '],\n",
       "       dtype=object),\n",
       " 'BRZNAME': array(['A029;Adebarweg;79;;;Altona;32004;',\n",
       "        'T200;Tristanweg;14;;Isoldeweg 9;Altona;32002;',\n",
       "        'W381;Wolfrunweg;11;;Siegrunweg 20;Altona;32003;', ...,\n",
       "        'B885;Brooktorpromenade;3;ca.;;Hamburg-Mitte;2001;103034',\n",
       "        'H474;Hirtenweg;1;ca.;;Altona;27008;219084',\n",
       "        'H474;Hirtenweg;2;ca.;;Altona;27008;219084'], dtype=object),\n",
       " 'LUMNUM': array([nan, 'uf0200001-Bodenrichtwert-Erlaeuterung1973.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1975.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1977.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1980.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1982.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1984.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1986.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1988.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1990.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1992.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1994.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1996.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung1998.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2000.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2002.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2004.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2006.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2008.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2010.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2011.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2012.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2013.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2014.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2015.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2016.pdf',\n",
       "        'uf0200001-Bodenrichtwert-Erlaeuterung2017.pdf'], dtype=object)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the remaining non-numerical columns\n",
    "non_numerical = pd.DataFrame(data.select_dtypes(exclude=\"number\").dtypes).reset_index()\n",
    "non_numerical\n",
    "\n",
    "unique = {}\n",
    "for column in non_numerical[\"index\"]: # list the unique values of the remaining non numerical columns\n",
    "    unique[column] = data[column].unique()\n",
    "unique\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are a few more columns that I can drop or convert:\n",
    "*   ORTST contains the district names, I will make it categorical\n",
    "*   STAG holds the date the real estate evaluation was done for, so convert it to datetime\n",
    "*   PLZ holds ZIP codes and can safely be converted to integer\n",
    "*   there appear to be some categorical variables, I will convert them to categorical format\n",
    "    - ENTW\n",
    "    - NUTA\n",
    "    - ERGNUTA\n",
    "    - BAUW\n",
    "    - VERG\n",
    "    - VERF\n",
    "*   FREI seems very messy, I will try to work without it for now\n",
    "*   BRZNAME holds only a few addresses, I will not need it for my analysis\n",
    "*   LUMNUM contains a reference to the PDF holding the corresponding metadata, should be safe to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "cols_to_drop = [\"FREI\", \"BRZNAME\", \"LUMNUM\"] # drop these columns\n",
    "data.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "data.ORTST = data.ORTST.astype(\"category\") # convert ORTST to category\n",
    "data.STAG = pd.to_datetime(data.STAG, format=\"%d.%m.%Y\") # convert STAG to datetime\n",
    "data.PLZ = pd.to_numeric(data.PLZ, downcast=\"integer\", errors=\"coerce\") # convert PLZ to numerical, it contains some strings\n",
    "# convert BASBE, ENTW, NUTA, ERGNUTA, BAUW, VERG, VERF, BEM to categorical\n",
    "to_convert = [\"ENTW\", \"NUTA\", \"ERGNUTA\", \"BAUW\", \"VERG\", \"VERF\"]\n",
    "for var in to_convert:\n",
    "    data[var] = data[var].astype(\"category\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there are any columns that only contain missing values. These can be dropped\n",
    "as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "for column in data:\n",
    "    if data[column].isnull().all():\n",
    "        data.drop(columns=column, inplace=True)\n",
    "        print(\"Dropped column \" + column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are some issues with the German Umlauts in ORTST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GroÃ Flottbek, SÃ¼lldorf, EimsbÃ¼ttel, GroÃ Borstel, Barmbek-SÃ¼d, ..., LohbrÃ¼gge, AllermÃ¶he, RÃ¶nneburg, EiÃendorf, NeuallermÃ¶he]\n",
       "Length: 14\n",
       "Categories (14, object): [GroÃ Flottbek, SÃ¼lldorf, EimsbÃ¼ttel, GroÃ Borstel, ..., AllermÃ¶he, RÃ¶nneburg, EiÃendorf, NeuallermÃ¶he]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ORTST.loc[data.ORTST.str.contains(\"Ã\")].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem seems to be wrong encoding:\n",
    "- \"ß\" has been replaced with \"Ã\"\n",
    "- \"ü\" has been replaced with \"Ã¼\"\n",
    "- \"ö\" has been replaced with \"Ã¶\"\n",
    "I will try to undo these changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rissen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iserbrook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Osdorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lurup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Othmarschen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bahrenfeld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eidelstedt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schnelsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hausbruch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stellingen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Eißendorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Altona-Nord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Altona-Altstadt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lokstedt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Niendorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Harburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>St. Pauli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hamburg-Altstadt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rotherbaum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Eppendorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Groß Borstel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Langenhorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wilstorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Langenbek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Wilhelmsburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Klostertor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Winterhude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fuhlsbüttel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Barmbek-Süd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hummelsbüttel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Hamm-Mitte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Hamm-Nord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Barmbek-Nord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Dulsberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Ochsenwerder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Tatenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Spadenland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Billbrook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Wellingsbüttel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Duvenstedt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Billstedt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Sasel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Bergstedt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Kirchwerder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Reitbrook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Billwerder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Volksdorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wohldorf-Ohlstedt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Neuengamme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Curslack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Altengamme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Altenwerder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Neuwerk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Sternschanze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Steinwerder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>HafenCity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Waltershof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Hamm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Neuallermöhe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0               Rissen\n",
       "1            Iserbrook\n",
       "2               Osdorf\n",
       "3                Lurup\n",
       "4          Othmarschen\n",
       "5           Bahrenfeld\n",
       "6           Eidelstedt\n",
       "7            Schnelsen\n",
       "8            Hausbruch\n",
       "9           Stellingen\n",
       "10           Eißendorf\n",
       "11         Altona-Nord\n",
       "12     Altona-Altstadt\n",
       "13            Lokstedt\n",
       "14            Niendorf\n",
       "15             Harburg\n",
       "16           St. Pauli\n",
       "17    Hamburg-Altstadt\n",
       "18          Rotherbaum\n",
       "19           Eppendorf\n",
       "20        Groß Borstel\n",
       "21          Langenhorn\n",
       "22            Wilstorf\n",
       "23           Langenbek\n",
       "24        Wilhelmsburg\n",
       "25          Klostertor\n",
       "26          Winterhude\n",
       "27         Fuhlsbüttel\n",
       "28         Barmbek-Süd\n",
       "29       Hummelsbüttel\n",
       "..                 ...\n",
       "78          Hamm-Mitte\n",
       "79           Hamm-Nord\n",
       "80        Barmbek-Nord\n",
       "81            Dulsberg\n",
       "82        Ochsenwerder\n",
       "83           Tatenberg\n",
       "84          Spadenland\n",
       "85           Billbrook\n",
       "86                Horn\n",
       "87      Wellingsbüttel\n",
       "88          Duvenstedt\n",
       "89           Billstedt\n",
       "90               Sasel\n",
       "91           Bergstedt\n",
       "92         Kirchwerder\n",
       "93           Reitbrook\n",
       "94          Billwerder\n",
       "95           Volksdorf\n",
       "96   Wohldorf-Ohlstedt\n",
       "97          Neuengamme\n",
       "98            Curslack\n",
       "99          Altengamme\n",
       "100        Altenwerder\n",
       "101            Neuwerk\n",
       "102       Sternschanze\n",
       "103        Steinwerder\n",
       "104          HafenCity\n",
       "105         Waltershof\n",
       "106               Hamm\n",
       "107       Neuallermöhe\n",
       "\n",
       "[108 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def revert_encoding(s):\n",
    "    if \"Ã¶\" in s:\n",
    "        return s.replace(\"Ã¶\", \"ö\")\n",
    "    if \"Ã¼\" in s:\n",
    "        return s.replace(\"Ã¼\", \"ü\")\n",
    "    if \"Ã\\x9f\" in s:\n",
    "        return s.replace(\"Ã\\x9f\", \"ß\")\n",
    "    return s\n",
    "\n",
    "data.ORTST = data.ORTST.apply(revert_encoding) # apply the new function to the ORSTS column\n",
    "data.ORTST = data.ORTST.astype(\"category\") # convert ORTST to category again\n",
    "pd.DataFrame(item for item in data.ORTST.unique()) # this looks much better!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The somewhat reduced dataset now looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2049911 entries, 0 to 2049910\n",
      "Data columns (total 17 columns):\n",
      "ORTST      category\n",
      "BRW        float64\n",
      "STAG       datetime64[ns]\n",
      "BRKE       int64\n",
      "PLZ        float64\n",
      "YWERT      int64\n",
      "XWERT      int64\n",
      "ENTW       category\n",
      "BEIT       float64\n",
      "NUTA       category\n",
      "ERGNUTA    category\n",
      "BAUW       category\n",
      "WGFZ       float64\n",
      "FLAE       float64\n",
      "GTIE       float64\n",
      "VERG       category\n",
      "VERF       category\n",
      "dtypes: category(7), datetime64[ns](1), float64(6), int64(3)\n",
      "memory usage: 170.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.head(5)\n",
    "data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the basic cleaning done, I can now store the dataset as a pickle file.\n",
    "Since it is still rather large, I will compress it after pickling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "data.to_pickle(\"../data/joined_ground_values.pkl.zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset for merging\n",
    " Assuming the data has been saved into ```../data/joined_ground_values.pkl``` before,\n",
    " it is possible to continue from this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../data/joined_ground_values.pkl.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the other dataset (district profiles) is on a district-year-level, I need to collapse this dataset\n",
    "over districts and years. For this step, it is important to know which variables\n",
    "can be collapsed in a meaningful way. For example, it does not make sense to\n",
    "collapse the zip codes using an average. Since my analysis will focus on the ground value,\n",
    "I will first collapse only this column by district (```ORTST```) and year (```STAG```). In\n",
    "the collapsed dataset, I will use the new column name ```GV``` for the ground value.\n",
    "Since the average of the ground values might be skewed by expensive clusters within\n",
    "districts, I will also include the median and some descriptive statistics while collapsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Paul/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GV_mean</th>\n",
       "      <th>GV_median</th>\n",
       "      <th>GV_std</th>\n",
       "      <th>GV_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Allermöhe</th>\n",
       "      <th>1964</th>\n",
       "      <td>13.420000</td>\n",
       "      <td>12.78</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>16.876000</td>\n",
       "      <td>17.90</td>\n",
       "      <td>1.402170</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>21.476000</td>\n",
       "      <td>23.01</td>\n",
       "      <td>2.285822</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>30.678000</td>\n",
       "      <td>30.68</td>\n",
       "      <td>3.616852</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>63.058889</td>\n",
       "      <td>51.13</td>\n",
       "      <td>26.689191</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GV_mean  GV_median     GV_std  GV_count\n",
       "district  year                                           \n",
       "Allermöhe 1964  13.420000      12.78   1.280000       4.0\n",
       "          1973  16.876000      17.90   1.402170       5.0\n",
       "          1975  21.476000      23.01   2.285822       5.0\n",
       "          1977  30.678000      30.68   3.616852       5.0\n",
       "          1980  63.058889      51.13  26.689191       9.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_collapse = data[[\"ORTST\", \"STAG\", \"BRW\"]]\n",
    "to_collapse.columns = [\"district\", \"year\", \"GV\"]\n",
    "to_collapse[\"year\"] = to_collapse[\"year\"].dt.year # preserve only the year for now\n",
    "\n",
    "collapsed = to_collapse.groupby([\"district\", \"year\"]).mean()\n",
    "collapsed.columns = [\"GV_mean\"]\n",
    "collapsed[\"GV_median\"] = to_collapse.groupby([\"district\", \"year\"]).median()\n",
    "collapsed[\"GV_std\"] = to_collapse.groupby([\"district\", \"year\"]).std()\n",
    "collapsed[\"GV_count\"] = to_collapse.groupby([\"district\", \"year\"]).count()[\"GV\"]\n",
    "collapsed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like everything went well! It is now time to store the finished dataset and\n",
    "continue with the data analysis (see ```data-analysis``` notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "collapsed.to_pickle(\"../data/collapsed_ground_values.pkl\") # holds collapsed data across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
