{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of District Profile and Ground Value data\n",
        " In this notebook, I will analyse the two datasets that I have cleaned in the\n",
        " notebooks ```notebook-district-profiles``` and ```notebook-ground-values```."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.formula.api as smf\n",
        "import math\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing and merging the data\n",
        " But first, I have to read and merge the two sets.\n",
        " I will first have to import the cleaned datasets. The district profiles dataset\n",
        " looks like this:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "profiles = pd.read_pickle(\"../data/cleaned_district_profiles_2007_2017.pkl\")\n",
        "profiles.head(5)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the ground values dataset looks like this:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ground_values = pd.read_pickle(\"../data/collapsed_ground_values.pkl\")\n",
        "ground_values.head(5)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like there are some districts that are not being matched:\n",
        "In the profiles dataset, some districts are listed combined, whereas they\n",
        "are listed individually in the ground values dataset. One example is \"Finkenwerder\",\n",
        "which occurs on its own in the ground values set and is listed as \"Waltershof\n",
        "und Finkenwerder\" in the district profiles dataset. In order to merge these\n",
        "instances into the district profiles, I will use the individual districts found in\n",
        "the ground values data to\n",
        "calculate means for each pair of district / year observations. For example,\n",
        "I will use the data for districts \"Finkenwerder\" and \"Waltershof\" to compute their\n",
        "average as \"Waltershof und Finkenwerder\", which I can then merge with the profiles\n",
        "dataset. These are the pair means I need to compute:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "check_districts = profiles.merge(   ground_values,\n",
        "                                    on=[\"district\", \"year\"],\n",
        "                                    indicator=True,\n",
        "                                    how=\"outer\")\n",
        "unmatched = check_districts[[\"district\", \"year\", \"_merge\"]][check_districts[\"district\"].str.contains(\"und\")]\n",
        "means_needed = {item.split(\" und \")[0]:item.split(\" und \")[1] for item in unmatched[\"district\"][:-1]}\n",
        "means_needed\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is actually calculating these means:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dict = {}\n",
        "for key, value in means_needed.items():\n",
        "    dict[key + \" und \" + value] = ground_values.loc[[key,value]].groupby(\"year\").mean()\n",
        "interpolated = pd.concat(dict)\n",
        "interpolated.index.rename([\"district\", \"year\"], inplace=True)\n",
        "interpolated.head()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I need to append these new instances to the existing ground value dataset:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ground_values = interpolated.append(ground_values)\n",
        "ground_values.info()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the ground values dataset includes the missing instances, I have to merge\n",
        "the two sets once more. This time, a left merge will be sufficient, as I only want\n",
        "to keep ground values for those districts for which profile data are available. The final\n",
        "DataFrame will have the name ```dd``` (District Dataset):"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dd = profiles.merge(ground_values,\n",
        "                    on=[\"district\", \"year\"],\n",
        "                    how=\"left\") # merge once more, this time as a left join\n",
        "\n",
        "dd.set_index([\"district\", \"year\"], inplace=True)\n",
        "dd.sort_values([\"district\", \"year\"], ascending=[True, True], inplace=True)\n",
        "dd.head()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the data cleaning and merging complete, I will save a copy of the dataset:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dd.to_pickle(\"../data/final_dataset.pkl\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis\n",
        " My eventual goal is to find out if and which sociodemographic features found in\n",
        " the district profiles dataset might be used to predict the mean or median estimated\n",
        " ground value of a district."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_pickle(\"../data/final_dataset.pkl\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing values\n",
        " But first, I will try to check the data for flaws that might still exist in the data\n",
        " after my initial cleaning. One such example are missing values.\n",
        " Since not all of the features have been observed in every year, there are many columns with a high share of\n",
        " missing values. These are the columns with a share of missing values that is $\\ge 50%$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "missing = dd.isnull().sum()/len(dd) # calculate share of missing values\n",
        "missing.sort_values(ascending=False, inplace=True)\n",
        "missing = missing.reset_index()\n",
        "missing.columns = [\"feature\", \"share_missing\"]\n",
        "fig = sns.barplot(x=\"feature\", y=\"share_missing\", data=missing.loc[missing.share_missing >= 0.5])\n",
        "plt.xticks(rotation=90)\n",
        "fig.set_title(\"Missing Values\")\n",
        "fig.set_ylabel(\"Share of missing values\")\n",
        "fig.set_xlabel(\"Feature\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although there are some columns that have a high share of missing data, I will try to\n",
        "keep them around for now. At this point, I am not sure if I can confidently drop any of\n",
        "these columns.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation with the ground value\n",
        " Since my main goal is predicting the ground value, I would like to see which district features are correlated with the ground value.\n",
        " To do this, I will calculate both the Pearson and Spearman correlation coefficients pairwise across\n",
        " my dataframe:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pearson = dd.corr()\n",
        "spearman = dd.corr(\"spearman\")\n",
        "corrs_w_GV = pd.DataFrame(pearson[\"GV_mean\"]) # correlations with mean ground value\n",
        "corrs_w_GV[\"spearman\"] = spearman[\"GV_mean\"]\n",
        "corrs_w_GV.columns = [\"pearson\", \"spearman\"]\n",
        "corrs_w_GV.sort_values(by=\"pearson\", ascending=False).head()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to be able to better compare the correlation results, I will plot both the Pearson\n",
        "and Spearman coefficients in the same barplot using this function:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "exclusion_list = [\"GV_mean\", \"GV_median\", \"GV_std\", \"GV_count\"] # exclude the descriptive stats\n",
        "\n",
        "def show_strongest_corr(type, negative, exclude=exclusion_list, n=10, target=\"Ground Value\", corr_df=corrs_w_GV):\n",
        "    \"\"\"Returns a barplot of the strongest correlations with the target variable\"\"\"\n",
        "    strongest = corr_df.drop(labels=exclude).sort_values(by=type, ascending=negative).head(n)\n",
        "    melted = strongest.reset_index().melt(\"index\", var_name=\"corr_type\", value_name=\"corr_coef\")\n",
        "    result = sns.barplot(x=\"index\", y=\"corr_coef\", hue=\"corr_type\", data=melted)\n",
        "    plt.xticks(rotation=90)\n",
        "    result.set_ylabel(\"Correlation Coefficient\" + \"\\n\" + \"ordered by \" + type[0])\n",
        "    result.set_xlabel(\"Variable\")\n",
        "    result.set_title(\"Strongest Correlations with \" + target)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the variables that have the strongest positive Pearson correlation with the mean ground value:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "show_strongest_corr(type=[\"pearson\", \"spearman\"], negative=False, n=10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And these the strongest positive Spearman correlations with the ground value:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "show_strongest_corr(type=[\"spearman\", \"pearson\"], negative=False, n=10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the strongest negative Pearson correlations with the mean ground value:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "show_strongest_corr(type=[\"pearson\", \"spearman\"], negative=True, n=10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And these the strongest negative Spearman correlations with the ground value:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "show_strongest_corr(type=[\"spearman\", \"pearson\"], negative=True, n=10)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variables with the strongest positive overall correlation with the ground value are the following:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sp_pearson = corrs_w_GV.drop(labels=exclusion_list).sort_values(by=[\"pearson\", \"spearman\"], ascending=False).head(15).reset_index()\n",
        "sp_spearman = corrs_w_GV.drop(labels=exclusion_list).sort_values(by=[\"spearman\", \"pearson\"], ascending=False).head(15).reset_index()\n",
        "sp = sp_pearson.merge(sp_spearman, on=\"index\", how=\"inner\")\n",
        "sp.iloc[:, 0:3]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These variables have the strongest negative overall correlation with the ground value:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sn_pearson = corrs_w_GV.drop(labels=exclusion_list).sort_values(by=[\"pearson\", \"spearman\"]).head(15).reset_index()\n",
        "sn_spearman = corrs_w_GV.drop(labels=exclusion_list).sort_values(by=[\"spearman\", \"pearson\"]).head(15).reset_index()\n",
        "sn = sn_pearson.merge(sn_spearman, on=\"index\", how=\"inner\")\n",
        "sn.iloc[:, 0:3]\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-Correlations of the potentially influential variables\n",
        " Since the variables might not only be correlated with the ground value, but also\n",
        " with one another, it makes sense to use pairplots to visualize these relationships.\n",
        " Among the variables with a positive correlation with the ground value, a few relationships\n",
        " are clearly visible:\n",
        " *   the general mean real estate price is correlated with the mean house price (by design of the feature)\n",
        " *   it is also correlated with the mean condo price\n",
        " *   it could also be that the share of single households in a ditrict is correlated with the mean real estate price"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# the relationship between the five strongest positive correlations with the ground value\n",
        "sns.pairplot(   data=dd,\n",
        "                vars=sp[\"index\"].head(5))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among the variables with a negative correlation with the ground value, it looks like\n",
        "*   the mean size of a household is strongly correlated with the share of children in the household,\n",
        "which makes intuitive sense\n",
        "*   household size is also correlated with the share of people under 18 in a district, which also seems plausible:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# the relationship between the five strongest negative correlations with the ground value\n",
        "sns.pairplot(   data=dd,\n",
        "                vars=sn[\"index\"].head(5))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Real Estate Price and Estimated Ground Value\n",
        " Let's turn back to the variables with a potential influence on the ground value. Although\n",
        " I have already computed the correlation coefficients, it can be beneficial to also\n",
        " examine the actual joint distribution. Here is an example for the most obvious positive correlation\n",
        " with the ground value, the mean real estate price. I am expecting a positive correlation because\n",
        " the ground value is supposed to estimate the mean sale price of a property. Both distributions\n",
        " are very similar in their long tail of high values / property prices:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fig = sns.jointplot(  x=\"real_estate_price_mean\",\n",
        "                y=\"GV_mean\",\n",
        "                data=dd.reset_index() )\n",
        "fig.set_axis_labels(\"Mean Real Estate Price\", \"Mean Ground Value\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This relationship seems to be stable over time as well:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=\"real_estate_price_mean\", y=\"GV_mean\", data=dd.reset_index(), hue=\"year\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take another look, broken down by year. In the years 2007 and 2009, the ground\n",
        "values were not estimated by the city:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.FacetGrid(dd.reset_index(), col=\"year\")\n",
        "g = g.map(plt.scatter, \"real_estate_price_mean\", \"GV_mean\", edgecolor=\"w\")\n",
        "g.set_xlabels(\"Mean Real Estate Price\")\n",
        "g.set_ylabels(\"Mean Ground Value\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All in all, there seems to be a consistently strong relationship between the two\n",
        "variables, making the ground value a good predictor of the actual real estate price.\n",
        "It thus fulfills its main objective:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(    x=\"real_estate_price_mean\",\n",
        "                y=\"GV_mean\",\n",
        "                data=dd)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution of the ground values: mean and median\n",
        " Since I am trying to predict the ground value (and indirectly also the real estate\n",
        " price) on a district level, it makes sense to analyse this variable's distribution.\n",
        " Let's start with an overview over the ground values across the most recent years:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=\"year\", y=\"GV_mean\", data=dd.reset_index())\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like the data from 2008 are distributed very differently from the data\n",
        "for the years from 2010 onwards, with outliers that reduce the readability of\n",
        "the other distributions. To get a better look, here is the data excluding the year\n",
        "2008:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=\"year\", y=\"GV_mean\", data=dd.reset_index().loc[dd.reset_index().year >= 2010])\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the majority of the districts has a relatively stable ground value,\n",
        "while the outlier districts keep getting ever more expensive. To support this argument,\n",
        "I need to look at the median ground values as well. Again, the 2008 distribution appears to\n",
        "be very different from the ones found in the later years:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=\"year\", y=\"GV_median\", data=dd.reset_index())\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, I plot the distribution for the more recent years excluding 2008.\n",
        "Here, too, it seems like the most drastic price increases are found among the\n",
        "outliers of the distribution:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(    x=\"year\",\n",
        "                y=\"GV_median\",\n",
        "                data=dd.reset_index().loc[dd.reset_index().year >= 2010])\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general trend actually seems to be mostly flat:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.regplot(    x=\"year\",\n",
        "                    y=\"GV_median\",\n",
        "                    data=dd.reset_index().loc[dd.reset_index().year >= 2010],\n",
        "                    robust=True )\n",
        "g.set_xlabel(\"Year\")\n",
        "g.set_ylabel(\"Median Ground Value\")\n",
        "g.set_title(\"Linear Model of Median Ground Value and Year, robust\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same seems to be true for the mean:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.regplot(    x=\"year\",\n",
        "                    y=\"GV_mean\",\n",
        "                    data=dd.reset_index().loc[dd.reset_index().year >= 2010],\n",
        "                    robust=True )\n",
        "g.set_xlabel(\"Year\")\n",
        "g.set_ylabel(\"Median Ground Value\")\n",
        "g.set_title(\"Linear Model of Mean Ground Value and Year, robust\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To sum up the current findings: while the majority of the districts of Hamburg\n",
        "generally does not see large increases in the ground value, the outliers seem\n",
        "be become more and more expensive. In order to further dive into this issue,\n",
        "I will have a look at the average increase in the ground value and identify those\n",
        "districts which experience exceptionally large increases. Since I have a gap in\n",
        "my ground values between 2008 and 2010, I will only look at the years 2011 and up.\n",
        "I decided to include the ```GV_count``` column, as it tells me how the size of\n",
        "the ground value dataset changed year on year."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "gv = dd[[\"GV_mean\", \"GV_median\", \"GV_count\"]].sort_values(  [\"district\", \"year\"],\\\n",
        "                                                            ascending=[True, True])\\\n",
        "                                             .groupby([\"district\"])\n",
        "abs_change = gv.diff()\n",
        "rel_change = gv.pct_change()\n",
        "abs_change.columns = list(map(lambda name: name + \"_abs\", abs_change.columns))\n",
        "rel_change.columns = list(map(lambda name: name + \"_rel\", rel_change.columns))\n",
        "changes = abs_change.join(rel_change)\n",
        "changes = changes.reset_index()\\\n",
        "                 .loc[changes.reset_index().year >= 2011]\\\n",
        "                 .set_index([\"district\", \"year\"])\n",
        "changes.head()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to identify the districts with above-average increases in ground value,\n",
        "I first have to compute the general average. In the ```year``` column, the values\n",
        "refer to the period ending with the year displayed. For example, 2011 means the\n",
        "change in the ground value from 2010 to 2011:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "changes.groupby(\"year\").mean()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the exception of 2013 and 2016, the general trend in the average change in the mean\n",
        "ground value is at around 5%. The median seems to keep up in 2010-11 and 2011-12, but lags\n",
        "behind the mean in 2013-14 and 2014-15. In 2013, the number of instances used to compute the\n",
        "median ground value dropped by 8%, which could explain the drop in the median and average\n",
        "ground value if there is data missing for some of the more expensive districts. Similarly,\n",
        "it could be the case that more expensive districts where added among the 2% increase in data points\n",
        "that happened in 2015-16. An increase in the median ground value of around 90% still seems very peculiar\n",
        "to me, though, as it is a robust measure that should not be affected this much when the number of\n",
        "instances grows by only 2%. I suspect a flaw in the data, that I will investigate further."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.lineplot(   data=changes.groupby(\"year\").mean()[[\"GV_mean_rel\", \"GV_median_rel\", \"GV_count_rel\"]],\n",
        "                    style=\"event\",\n",
        "                    markers=True)\n",
        "g.set_xlabel(\"Year\")\n",
        "g.set_ylabel(\"Relative Change\")\n",
        "g.legend([\"Mean Ground Value\", \"Median Ground Value\", \"# of data points\"])\n",
        "g.set_title(\"Relative y-o-y change in mean and median ground value\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My goal is to find out which district out- or underperfomed their counterparts\n",
        "over the course of my observation period. In order to do this, I have to\n",
        "calculate the difference between the average change in the median ground value\n",
        "across all districts and the change in the median ground value inside a particularl\n",
        "district. Then, I count the number of years in which this difference was positive\n",
        "(for the outperformers) or the number of years in which this difference was negative\n",
        "(in the case of the underperformers). I am again using the median as my measure of\n",
        "centrality, because some of the changes are much too large to be plausible and I\n",
        "do not want these values to skew my overall trends:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cm = changes.join(changes.groupby(\"year\").median(), rsuffix=\"_avg_change\")\n",
        "cm = cm[[\"GV_mean_rel\", \"GV_median_rel\", \"GV_mean_rel_avg_change\", \"GV_median_rel_avg_change\"]]\n",
        "cm[\"diff_from_mean\"] = cm[\"GV_mean_rel\"] - cm[\"GV_mean_rel_avg_change\"]\n",
        "cm[\"diff_from_median\"] = cm[\"GV_median_rel\"] - cm[\"GV_median_rel_avg_change\"]\n",
        "no_of_periods = len(cm.index.levels[-1]) # keep track of the total number of periods\n",
        "cm.head()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the district/year combinations with the largest positive difference between\n",
        "the median change in the median ground value. These values signify the cases\n",
        "where a district outperformed the median change in median ground value:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cm.sort_values(by=\"diff_from_median\", ascending=False)[\"diff_from_median\"].head(15) # greatest outperformers in terms of change in median\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the district/year combinations with the largest negative difference between\n",
        "the median change in the median ground value. These values signify the cases\n",
        "where a district underperformed the median change in median ground value:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cm.sort_values(by=\"diff_from_median\", ascending=True)[\"diff_from_median\"].head(15) # greatest underperformers in terms of change in median\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to better visualize these resuls and find potential spatial clusters,\n",
        "I would like to show my results overlayed onto a map of the city. For this,\n",
        "I will use the shapefiles I have cleaned in the ```spatial``` notebook. I will\n",
        "use Geopandas to import the shapefiles and append my data to the GeoDataFrame, which\n",
        "I can then plot:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas\n",
        "geodata = pd.read_pickle(\"../data/geodata.pkl\")\n",
        "cm[\"median_performance\"] = np.where(cm[\"diff_from_median\"] > 0, 1, -1) # 1 if outperformed, -1 if underperformed\n",
        "perf = cm.groupby(\"district\")[\"median_performance\"].sum().sort_values(ascending=False)\n",
        "perf = pd.DataFrame(perf)\n",
        "perf[\"share_periods\"] = perf[\"median_performance\"] / no_of_periods\n",
        "perf_geo = geodata.merge(perf, on=\"district\", how=\"right\") # merge shapefiles in\n",
        "perf_geo.head()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following plot summarizes my results: the districts are coloured according\n",
        "to a scale between -1 and 1. A value of 1 would mean that the district's change\n",
        "in median ground value exceeded (and thus outperformed) the median of the change\n",
        "in median ground value calculated across all districts *in every single one of the 7\n",
        "periods*. A value of -1 would mean that the district underperformed the median in\n",
        "*in all of the 7 periods the differences were calculated for*. The seven periods\n",
        "are the differences from 2010-11, 2011-12 and so on.\n",
        "Based on this map, I can draw a few conclusions:\n",
        "*   the district which is most constently outperforming its peers is \"Sternschanze\",\n",
        "which has been heavily gentrifying over the course of the last ten years and is still a very\n",
        "attractive location\n",
        "*   the districts in the South of the city have all experienced underperformant growth,\n",
        "which could be due to the many industrial areas south of the river Elbe.\n",
        "* in general, centrality seems to be a driving factor in determining the ground value performance\n",
        "of a district, although there are outliers such as the district in the Northeast"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "g = perf_geo.plot(  column=\"share_periods\",\n",
        "                    legend=True,\n",
        "                    figsize=(20, 10))\n",
        "g.set_title(\"Share of years of over/underperformance\" + \"\\n\" + \"in terms of change in median\" + \"\\n\" + \"ground value, 2010 to 2017\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Next steps\n",
        " Now that I have found a way to identify the districts that performed better than\n",
        " their counterparts, my next goal is to find statistical evidence of the factors\n",
        " which enabled their superior performance. One idea would be to work an a logistical\n",
        " regression with an outperformance dummy as the dependent variable and the district\n",
        " features of the previous period as the independent variables. Another idea would be\n",
        " a machine learning model that tries to apply binary classification to the same\n",
        " problem. I will address these ideas in the next project report. "
      ],
      "metadata": {}
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}